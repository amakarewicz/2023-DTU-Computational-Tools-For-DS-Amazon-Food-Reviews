{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from signatures_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([pd.read_feather('data/text_df_1.feather'),\n",
    "                  pd.read_feather('data/text_df_2.feather'),\n",
    "                  pd.read_feather('data/text_df_3.feather')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28422, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample = data.sample(int(len(data)/20), random_state=123)\n",
    "data_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_clean = re.compile(r'[\\d.,!?;:@#&]+|<[^>]*>|https?://\\S+|[\"\\'\\(\\)_/+\\\\$-]')\n",
    "data_sample['Cleaner_text'] = (\n",
    "    data_sample['Text']\n",
    "    .apply(lambda x: html_clean.sub(r' ',x))\n",
    "    .apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    ")\n",
    "\n",
    "data_sample['Ngrams'] = (\n",
    "    data_sample['Cleaner_text']\n",
    "    .apply(lambda x: set(list(nltk.ngrams(x.lower().split(), 2))))\n",
    "    .apply(lambda x: [\" \".join(w) for w in x])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg = data_sample[['UserId', 'Ngrams']].groupby('UserId').apply('sum')\n",
    "data_agg['Ngrams'] = data_agg['Ngrams'].apply(lambda x: set(x))\n",
    "\n",
    "k=100\n",
    "data_agg['Minhash'] = data_agg['Ngrams'].apply(lambda x: minhash2(x, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg = data_agg.reset_index()\n",
    "data_agg.to_csv('data/sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24556/24556 [2:10:29<00:00,  3.14it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668550\n",
      "301510846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "seed = 123\n",
    "jaccard_threshold = 0.035\n",
    "\n",
    "lsh_dict = dict(zip(data_agg.index, data_agg.Minhash))\n",
    "list_keys = list(lsh_dict.keys())\n",
    "\n",
    "similar_items = {}\n",
    "count = 0\n",
    "for i in tqdm(range(len(list_keys)-1)):\n",
    "    for j in range(i+1, len(list_keys)):\n",
    "        count +=1\n",
    "        common_values = np.intersect1d(lsh_dict[list_keys[i]], lsh_dict[list_keys[j]])\n",
    "        if len(common_values) > 0:\n",
    "            # we found a candidate\n",
    "            similarity_score = jaccard(list_keys[i], list_keys[j], lsh_dict)\n",
    "            if similarity_score > jaccard_threshold:\n",
    "                # print(similarity_score)\n",
    "                similar_items[(list_keys[i], list_keys[j])] = similarity_score\n",
    "print(len(similar_items))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\DTU\\2023-DTU-Computational-Tools-For-DS-Amazon-Food-Reviews\\signatures.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DTU/2023-DTU-Computational-Tools-For-DS-Amazon-Food-Reviews/signatures.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m similar_items \u001b[39m=\u001b[39m {}\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DTU/2023-DTU-Computational-Tools-For-DS-Amazon-Food-Reviews/signatures.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/DTU/2023-DTU-Computational-Tools-For-DS-Amazon-Food-Reviews/signatures.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m pairs \u001b[39m=\u001b[39m [(i, j) \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(list_keys)\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m j \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39mlen\u001b[39;49m(list_keys))]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DTU/2023-DTU-Computational-Tools-For-DS-Amazon-Food-Reviews/signatures.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mwith\u001b[39;00m ProcessPoolExecutor() \u001b[39mas\u001b[39;00m executor:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DTU/2023-DTU-Computational-Tools-For-DS-Amazon-Food-Reviews/signatures.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(tqdm(executor\u001b[39m.\u001b[39mimap(process_pair, pairs), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(pairs)))\n",
      "\u001b[1;32md:\\DTU\\2023-DTU-Computational-Tools-For-DS-Amazon-Food-Reviews\\signatures.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DTU/2023-DTU-Computational-Tools-For-DS-Amazon-Food-Reviews/signatures.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m similar_items \u001b[39m=\u001b[39m {}\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DTU/2023-DTU-Computational-Tools-For-DS-Amazon-Food-Reviews/signatures.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/DTU/2023-DTU-Computational-Tools-For-DS-Amazon-Food-Reviews/signatures.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m pairs \u001b[39m=\u001b[39m [(i, j) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(list_keys)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(list_keys))]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DTU/2023-DTU-Computational-Tools-For-DS-Amazon-Food-Reviews/signatures.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mwith\u001b[39;00m ProcessPoolExecutor() \u001b[39mas\u001b[39;00m executor:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DTU/2023-DTU-Computational-Tools-For-DS-Amazon-Food-Reviews/signatures.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(tqdm(executor\u001b[39m.\u001b[39mimap(process_pair, pairs), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(pairs)))\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# seed = 123\n",
    "# jaccard_threshold = 0.035\n",
    "\n",
    "# lsh_dict = dict(zip(data_agg.index, data_agg.Minhash))\n",
    "# list_keys = list(lsh_dict.keys())\n",
    "\n",
    "# def process_pair(pair):\n",
    "#     i, j = pair\n",
    "#     common_values = np.intersect1d(lsh_dict[list_keys[i]], lsh_dict[list_keys[j]])\n",
    "#     if len(common_values) > 0:\n",
    "#         similarity_score = jaccard(list_keys[i], list_keys[j], lsh_dict)\n",
    "#         if similarity_score > jaccard_threshold:\n",
    "#             return (list_keys[i], list_keys[j]), similarity_score\n",
    "#     return None\n",
    "\n",
    "# similar_items = {}\n",
    "# count = 0\n",
    "\n",
    "# pairs = [(i, j) for i in range(len(list_keys)-1) for j in range(i+1, len(list_keys))]\n",
    "\n",
    "# with ProcessPoolExecutor() as executor:\n",
    "#     results = list(tqdm(executor.imap(process_pair, pairs), total=len(pairs)))\n",
    "\n",
    "# for result in results:\n",
    "#     if result:\n",
    "#         similar_items[result[0]] = result[1]\n",
    "#         count += 1\n",
    "\n",
    "# print(len(similar_items))\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_items_new = {data_agg.UserId[k[0]]+\"|\"+data_agg.UserId[k[1]]:v for k, v in similar_items.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create json object from dictionary\n",
    "import json\n",
    "json = json.dumps(similar_items_new)\n",
    "\n",
    "# open file for writing, \"w\" \n",
    "f = open(\"data/similarity_dict.json\",\"w\")\n",
    "\n",
    "# write json object to file\n",
    "f.write(json)\n",
    "\n",
    "# close file\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socialgraphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
